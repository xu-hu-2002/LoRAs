# å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯é›†åˆ (PEFT Collection)

åŸºäºHuggingFace PEFTåº“çš„äº”ç§ä¸»æµå‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯ç»Ÿä¸€å®ç°ï¼Œä¸“ä¸ºTriviaQAå’ŒNQ Openæ•°æ®é›†è®­ç»ƒä¼˜åŒ–ã€‚


## ğŸ“ é¡¹ç›®ç»“æ„

```
LoRA/
â”œâ”€â”€ LoRA/
â”‚   â””â”€â”€ lora_hf.py          # LoRA - HuggingFace PEFTå®ç°
â”œâ”€â”€ DoRA/
â”‚   â””â”€â”€ dora_hf.py          # DoRA - HuggingFace PEFTå®ç°
â”œâ”€â”€ QLoRA/
â”‚   â””â”€â”€ qlora_hf.py         # QLoRA - HuggingFace PEFTå®ç°
â”œâ”€â”€ PiSSA/
â”‚   â””â”€â”€ pissa_hf.py         # PiSSA - HuggingFace PEFTå®ç°
â”œâ”€â”€ AdaLoRA/
â”‚   â”œâ”€â”€ adalora.py          # AdaLoRAæ ¸å¿ƒå®ç°ï¼ˆç‹¬ç«‹ï¼‰
â”‚   â””â”€â”€ adalora_config.py   # AdaLoRAé…ç½®
â”œâ”€â”€ common/
â”‚   â”œâ”€â”€ data_preprocessing.py  # å…±äº«æ•°æ®é¢„å¤„ç†
â”‚   â””â”€â”€ training_utils.py      # å…±äº«è®­ç»ƒå·¥å…·
â”œâ”€â”€ example_usage.py        # å®Œæ•´ä½¿ç”¨ç¤ºä¾‹
â”œâ”€â”€ requirements.txt        # ä¾èµ–è¦æ±‚
â””â”€â”€ README.md              # æœ¬æ–‡æ¡£
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 2. è¿è¡Œæ¼”ç¤º

```bash
python example_usage.py
```

### 3. åŸºæœ¬ä½¿ç”¨

```python
# ä»¥LoRAä¸ºä¾‹
from LoRA.lora_hf import create_lora_config, load_model_with_lora
from common.data_preprocessing import create_qa_dataset
from common.training_utils import train_model

# 1. åˆ›å»ºé…ç½®
config = create_lora_config(r=128, lora_alpha=256) 

# 2. åŠ è½½æ¨¡å‹
model, tokenizer = load_model_with_lora(size="medium")  # ä½¿ç”¨configæ¨èçš„Llama-3.2-3B

# 3. å‡†å¤‡æ•°æ®
dataset = create_qa_dataset("triviaqa", tokenizer, max_samples=1000) 

# 4. è®­ç»ƒ
trainer = train_model(model, tokenizer, dataset)
```

## ğŸ”§ æ”¯æŒçš„æŠ€æœ¯

### 1. LoRA (Low-Rank Adaptation)
```python
from LoRA.lora_hf import create_lora_config, load_model_with_lora

config = create_lora_config(
    r=128,                    # rank
    lora_alpha=256,          # 2 * r
    lora_dropout=0.1,
    target_modules=["q_proj", "v_proj", "k_proj", "o_proj", 
                   "gate_proj", "up_proj", "down_proj"]
)
model, tokenizer = load_model_with_lora("model_name", config)
```

### 2. DoRA (Weight-Decomposed Low-Rank Adaptation)
```python
from DoRA.dora_hf import create_dora_config, load_model_with_dora

config = create_dora_config(
    r=128,
    lora_alpha=256,
    use_dora=True,           # å…³é”®ï¼šå¯ç”¨DoRA
    target_modules=["q_proj", "v_proj", "k_proj", "o_proj",
                   "gate_proj", "up_proj", "down_proj"]
)
model, tokenizer = load_model_with_dora("model_name", config)
```

### 3. QLoRA (4-bit Quantized LoRA)
```python
from QLoRA.qlora_hf import create_qlora_config, load_model_with_qlora, create_bnb_config

# é‡åŒ–é…ç½®
bnb_config = create_bnb_config(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16
)

# LoRAé…ç½®
qlora_config = create_qlora_config(r=128, lora_alpha=256)

model, tokenizer = load_model_with_qlora("model_name", qlora_config, bnb_config)
```

### 4. PiSSA (Principal Singular Values and Singular Vectors Adaptation)
```python
from PiSSA.pissa_hf import create_pissa_config, load_model_with_pissa

config = create_pissa_config(
    r=128,
    lora_alpha=256,
    lora_dropout=0.0,        # PiSSAæ¨èè®¾ä¸º0
    init_lora_weights="pissa_niter_4"  # SVDåˆå§‹åŒ–
)
model, tokenizer = load_model_with_pissa("model_name", config)
```

### 5. AdaLoRA (Adaptive Budget Allocation)
```python
from AdaLoRA.adalora_config import AdaLoRAConfig
from AdaLoRA.adalora import RankAllocator

config = AdaLoRAConfig(
    r=12,
    target_rank=8,
    init_warmup=500,
    final_warmup=1500,
    mask_interval=10
)
# æ³¨æ„ï¼šAdaLoRAéœ€è¦ç‰¹æ®Šçš„è®­ç»ƒå¾ªç¯
```

## ğŸ“Š æ•°æ®å¤„ç†

### æ”¯æŒçš„æ•°æ®é›†
- **TriviaQA**: é€šç”¨çŸ¥è¯†é—®ç­”æ•°æ®é›†
- **Natural Questions (NQ Open)**: åŸºäºç»´åŸºç™¾ç§‘çš„å¼€æ”¾åŸŸé—®ç­”

### æ•°æ®é¢„å¤„ç†
```python
from common.data_preprocessing import create_qa_dataset

# TriviaQA
trivia_dataset = create_qa_dataset(
    "triviaqa", 
    tokenizer, 
    split="train",
    max_samples=5000
)

# Natural Questions
nq_dataset = create_qa_dataset(
    "natural_questions", 
    tokenizer, 
    split="train", 
    max_samples=5000
)

# ç¤ºä¾‹æ•°æ®ï¼ˆç”¨äºæµ‹è¯•ï¼‰
sample_dataset = create_sample_qa_dataset(tokenizer, num_samples=10)
```

## ğŸ‹ï¸ è®­ç»ƒé…ç½®

### é»˜è®¤è®­ç»ƒå‚æ•°
```python
from common.training_utils import create_training_arguments, train_model

training_args = create_training_arguments(
    output_dir="./results",
    num_train_epochs=3,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=2,
    learning_rate=2e-4,      # PEFTæ¨èå­¦ä¹ ç‡
    warmup_steps=100,
    fp16=True,               # æ··åˆç²¾åº¦è®­ç»ƒ
    logging_steps=10,
    save_steps=500
)

trainer = train_model(model, tokenizer, dataset, training_args=training_args)
```


## ğŸ’¡ é€‰æ‹©å»ºè®® ï¼ˆå¾…å®š)

- **å¿«é€Ÿå®éªŒ**: LoRA
- **æ€§èƒ½ä¼˜å…ˆ**: DoRA æˆ– PiSSA
- **æ˜¾å­˜å—é™**: QLoRA
- **å‚æ•°æ•ˆç‡**: AdaLoRA
- **æœ€ä½³å®è·µ**: PiSSA + QLoRA ç»„åˆ

## ğŸ”§ é«˜çº§ç”¨æ³•

### ä¿å­˜å’ŒåŠ è½½æ¨¡å‹
```python
from common.training_utils import save_model_and_adapter

# ä¿å­˜é€‚é…å™¨ï¼ˆæ¨èï¼‰
save_model_and_adapter(model, tokenizer, "./my_adapter", save_adapter_only=True)

# åŠ è½½é€‚é…å™¨
from peft import PeftModel
base_model = AutoModelForCausalLM.from_pretrained("base_model_name")
model = PeftModel.from_pretrained(base_model, "./my_adapter")
```

### æ¨¡å‹è¯„ä¼°
```python
from common.training_utils import evaluate_model, generate_text

# è¯„ä¼°
metrics = evaluate_model(model, tokenizer, eval_dataset)
print(f"Loss: {metrics['eval_loss']:.4f}")

# ç”Ÿæˆ
response = generate_text(
    model, tokenizer, 
    "Question: What is the capital of France?",
    max_new_tokens=50
)
print(response)
```


## ğŸ“‹ ä¾èµ–è¦æ±‚

- Python 3.8+
- PyTorch 2.0+
- Transformers 4.36+
- PEFT 0.8+
- BitsAndBytes 0.42+ (ç”¨äºQLoRA)
- Datasets 2.14+

è¯¦è§ `requirements.txt`


## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. **LoRA**: [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)
2. **DoRA**: [DoRA: Weight-Decomposed Low-Rank Adaptation](https://arxiv.org/abs/2402.09353)
3. **QLoRA**: [QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314)
4. **PiSSA**: [PiSSA: Principal Singular Values and Singular Vectors Adaptation](https://arxiv.org/abs/2404.02948)
5. **AdaLoRA**: [Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2303.10512)
